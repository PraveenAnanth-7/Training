{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f14856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffbe7883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\praveen ananth\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow_datasets) (2.2.1)\n",
      "Collecting dm-tree (from tensorflow_datasets)\n",
      "  Downloading dm_tree-0.1.9-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting etils>=1.9.1 (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets)\n",
      "  Downloading etils-1.12.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting immutabledict (from tensorflow_datasets)\n",
      "  Downloading immutabledict-4.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (5.29.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (6.1.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (19.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (2.32.3)\n",
      "Collecting simple_parsing (from tensorflow_datasets)\n",
      "  Downloading simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Downloading tensorflow_metadata-1.17.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\praveen ananth\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow_datasets) (2.5.0)\n",
      "Requirement already satisfied: toml in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (4.67.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (1.17.2)\n",
      "Collecting einops (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (2025.3.0)\n",
      "Collecting importlib_resources (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (4.12.2)\n",
      "Requirement already satisfied: zipp in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2024.7.4)\n",
      "Requirement already satisfied: attrs>=18.2.0 in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dm-tree->tensorflow_datasets) (24.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from simple_parsing->tensorflow_datasets)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow_datasets)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\praveen ananth\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->tensorflow_datasets) (0.4.6)\n",
      "Downloading tensorflow_datasets-4.9.8-py3-none-any.whl (5.3 MB)\n",
      "   ---------------------------------------- 0.0/5.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/5.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/5.3 MB 1.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.8/5.3 MB 1.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.0/5.3 MB 1.3 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.3/5.3 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.6/5.3 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 1.8/5.3 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.1/5.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.4/5.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 2.6/5.3 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 2.9/5.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.1/5.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 3.4/5.3 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.7/5.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 3.9/5.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 4.2/5.3 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.5/5.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.7/5.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.0/5.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.2/5.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.3/5.3 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading etils-1.12.2-py3-none-any.whl (167 kB)\n",
      "Downloading dm_tree-0.1.9-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Downloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\n",
      "Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
      "Downloading tensorflow_metadata-1.17.1-py3-none-any.whl (31 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21544 sha256=423ad4874de712f5f0ae1bbfdbdf74dda43b654dcc9fd123f6addcec82f8ddd7\n",
      "  Stored in directory: c:\\users\\praveen ananth\\appdata\\local\\pip\\cache\\wheels\\e7\\e6\\28\\864bdfee5339dbd6ddcb5a186286a8e217648ec198bdf0097d\n",
      "Successfully built promise\n",
      "Installing collected packages: promise, importlib_resources, immutabledict, googleapis-common-protos, etils, einops, docstring-parser, dm-tree, tensorflow-metadata, simple_parsing, tensorflow_datasets\n",
      "Successfully installed dm-tree-0.1.9 docstring-parser-0.16 einops-0.8.1 etils-1.12.2 googleapis-common-protos-1.70.0 immutabledict-4.2.1 importlib_resources-6.5.2 promise-2.3 simple_parsing-0.1.7 tensorflow-metadata-1.17.1 tensorflow_datasets-4.9.8\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e1cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd654ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRAVEEN ANANTH\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8266 - loss: 0.6229 - val_accuracy: 0.9466 - val_loss: 0.1899\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.1745 - val_accuracy: 0.9603 - val_loss: 0.1335\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.1228 - val_accuracy: 0.9661 - val_loss: 0.1123\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9727 - loss: 0.0939 - val_accuracy: 0.9719 - val_loss: 0.0942\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0743 - val_accuracy: 0.9749 - val_loss: 0.0835\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.0582 - val_accuracy: 0.9748 - val_loss: 0.0815\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0481 - val_accuracy: 0.9768 - val_loss: 0.0758\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0407 - val_accuracy: 0.9783 - val_loss: 0.0723\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0341 - val_accuracy: 0.9763 - val_loss: 0.0773\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0302 - val_accuracy: 0.9777 - val_loss: 0.0754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1766352e570>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_img(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# 5. Train the model\n",
    "model.fit(ds_train, epochs=10, callbacks=[tensorboard_callback], validation_data=ds_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
